<!DOCTYPE HTML>
<html lang="null">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="单身程序员的小窝">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->

    <meta name="keywords" content="Machine Learning">


    <meta name="description" content="机器学习纳米学位非监督学习项目 3: 创建用户分类欢迎来到机器学习工程师纳米学位的第三个项目！在这个 notebook 文件中，有些模板代码已经提供给你，但你还需要实现更多的功能来完成这个项目。...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>Customer Setments | 单身程序员的小窝</title>


    <link rel="alternate" href="/atom.xml" title="单身程序员的小窝" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>






    

</head>


</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner2.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="Jindong">
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                <h2> 科技让复杂的世界更简单! </h2>
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">单身程序员的小窝</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>Home</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/机器学习/"><i class="fa "></i>MachineLearning</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/深度学习/"><i class="fa "></i>DeepLearning</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tools/"><i class="fa "></i>Tools</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>History</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="Customer Setments">
            
	            Customer Setments
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/机器学习/">机器学习</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/02/16</span>
        </span>
        
    
</div>
            
            
    </div>
    
    <div class="post-body post-content">
        <h1 id="机器学习纳米学位"><a href="#机器学习纳米学位" class="headerlink" title="机器学习纳米学位"></a>机器学习纳米学位</h1><h2 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h2><h2 id="项目-3-创建用户分类"><a href="#项目-3-创建用户分类" class="headerlink" title="项目 3: 创建用户分类"></a>项目 3: 创建用户分类</h2><p>欢迎来到机器学习工程师纳米学位的第三个项目！在这个 notebook 文件中，有些模板代码已经提供给你，但你还需要实现更多的功能来完成这个项目。除非有明确要求，你无须修改任何已给出的代码。以<strong>‘练习’</strong>开始的标题表示接下来的代码部分中有你必须要实现的功能。每一部分都会有详细的指导，需要实现的部分也会在注释中以 <strong>‘TODO’</strong> 标出。请仔细阅读所有的提示！</p>
<p>除了实现代码外，你还<strong>必须</strong>回答一些与项目和你的实现有关的问题。每一个需要你回答的问题都会以<strong>‘问题 X’</strong>为标题。请仔细阅读每个问题，并且在问题后的<strong>‘回答’</strong>文字框中写出完整的答案。我们将根据你对问题的回答和撰写代码所实现的功能来对你提交的项目进行评分。</p>
<blockquote>
<p><strong>提示：</strong>Code 和 Markdown 区域可通过 <strong>Shift + Enter</strong> 快捷键运行。此外，Markdown 可以通过双击进入编辑模式。</p>
</blockquote>
<h2 id="开始"><a href="#开始" class="headerlink" title="开始"></a>开始</h2><p>在这个项目中，你将分析一个数据集的内在结构，这个数据集包含很多客户真对不同类型产品的年度采购额（用<strong>金额</strong>表示）。这个项目的任务之一是如何最好地描述一个批发商不同种类顾客之间的差异。这样做将能够使得批发商能够更好的组织他们的物流服务以满足每个客户的需求。</p>
<p>这个项目的数据集能够在<a href="https://archive.ics.uci.edu/ml/datasets/Wholesale+customers" target="_blank" rel="noopener">UCI机器学习信息库</a>中找到.因为这个项目的目的，分析将不会包括 ‘Channel’ 和 ‘Region’ 这两个特征——重点集中在6个记录的客户购买的产品类别上。</p>
<p>运行下面的的代码单元以载入整个客户数据集和一些这个项目需要的 Python 库。如果你的数据集载入成功，你将看到后面输出数据集的大小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 检查你的Python版本</span></span><br><span class="line"><span class="keyword">from</span> sys <span class="keyword">import</span> version_info</span><br><span class="line"><span class="keyword">if</span> version_info.major != <span class="number">3</span>:</span><br><span class="line">    <span class="keyword">raise</span> Exception(<span class="string">'请使用Python 3.x 来完成此项目'</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 引入这个项目需要的库</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> visuals <span class="keyword">as</span> vs</span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> display <span class="comment"># 使得我们可以对DataFrame使用display()函数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置以内联的形式显示matplotlib绘制的图片（在notebook中显示更美观）</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="comment"># 高分辨率显示</span></span><br><span class="line">%config InlineBackend.figure_format=<span class="string">'retina'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入整个客户数据集</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    data = pd.read_csv(<span class="string">"customers.csv"</span>)</span><br><span class="line">    data.drop([<span class="string">'Region'</span>, <span class="string">'Channel'</span>], axis = <span class="number">1</span>, inplace = <span class="keyword">True</span>)</span><br><span class="line">    print(<span class="string">"Wholesale customers dataset has &#123;&#125; samples with &#123;&#125; features each."</span>.format(*data.shape))</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    print(<span class="string">"Dataset could not be loaded. Is the dataset missing?"</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Wholesale customers dataset has 440 samples with 6 features each.
</code></pre><h2 id="分析数据"><a href="#分析数据" class="headerlink" title="分析数据"></a>分析数据</h2><p>在这部分，你将开始分析数据，通过可视化和代码来理解每一个特征和其他特征的联系。你会看到关于数据集的统计描述，考虑每一个属性的相关性，然后从数据集中选择若干个样本数据点，你将在整个项目中一直跟踪研究这几个数据点。</p>
<p>运行下面的代码单元给出数据集的一个统计描述。注意这个数据集包含了6个重要的产品类型：<strong>‘Fresh’</strong>, <strong>‘Milk’</strong>, <strong>‘Grocery’</strong>, <strong>‘Frozen’</strong>, <strong>‘Detergents_Paper’</strong>和 <strong>‘Delicatessen’</strong>。想一下这里每一个类型代表你会购买什么样的产品。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示数据集的一个描述</span></span><br><span class="line">display(data.describe())</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>440.000000</td>
      <td>440.000000</td>
      <td>440.000000</td>
      <td>440.000000</td>
      <td>440.000000</td>
      <td>440.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>12000.297727</td>
      <td>5796.265909</td>
      <td>7951.277273</td>
      <td>3071.931818</td>
      <td>2881.493182</td>
      <td>1524.870455</td>
    </tr>
    <tr>
      <th>std</th>
      <td>12647.328865</td>
      <td>7380.377175</td>
      <td>9503.162829</td>
      <td>4854.673333</td>
      <td>4767.854448</td>
      <td>2820.105937</td>
    </tr>
    <tr>
      <th>min</th>
      <td>3.000000</td>
      <td>55.000000</td>
      <td>3.000000</td>
      <td>25.000000</td>
      <td>3.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>3127.750000</td>
      <td>1533.000000</td>
      <td>2153.000000</td>
      <td>742.250000</td>
      <td>256.750000</td>
      <td>408.250000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>8504.000000</td>
      <td>3627.000000</td>
      <td>4755.500000</td>
      <td>1526.000000</td>
      <td>816.500000</td>
      <td>965.500000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>16933.750000</td>
      <td>7190.250000</td>
      <td>10655.750000</td>
      <td>3554.250000</td>
      <td>3922.000000</td>
      <td>1820.250000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>112151.000000</td>
      <td>73498.000000</td>
      <td>92780.000000</td>
      <td>60869.000000</td>
      <td>40827.000000</td>
      <td>47943.000000</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="练习-选择样本"><a href="#练习-选择样本" class="headerlink" title="练习: 选择样本"></a>练习: 选择样本</h3><p>为了对客户有一个更好的了解，并且了解代表他们的数据将会在这个分析过程中如何变换。最好是选择几个样本数据点，并且更为详细地分析它们。在下面的代码单元中，选择<strong>三个</strong>索引加入到索引列表<code>indices</code>中，这三个索引代表你要追踪的客户。我们建议你不断尝试，直到找到三个明显不同的客户。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：从数据集中选择三个你希望抽样的数据点的索引</span></span><br><span class="line">indices = [<span class="number">1</span>, <span class="number">14</span>, <span class="number">168</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为选择的样本建立一个DataFrame</span></span><br><span class="line">samples = pd.DataFrame(data.loc[indices], columns = data.keys()).reset_index(drop = <span class="keyword">True</span>)</span><br><span class="line">print(<span class="string">"Chosen samples of wholesale customers dataset:"</span>)</span><br><span class="line">display(samples)</span><br></pre></td></tr></table></figure>
<pre><code>Chosen samples of wholesale customers dataset:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7057</td>
      <td>9810</td>
      <td>9568</td>
      <td>1762</td>
      <td>3293</td>
      <td>1776</td>
    </tr>
    <tr>
      <th>1</th>
      <td>24653</td>
      <td>9465</td>
      <td>12091</td>
      <td>294</td>
      <td>5058</td>
      <td>2168</td>
    </tr>
    <tr>
      <th>2</th>
      <td>5809</td>
      <td>735</td>
      <td>803</td>
      <td>1393</td>
      <td>79</td>
      <td>429</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="问题-1"><a href="#问题-1" class="headerlink" title="问题 1"></a>问题 1</h3><p>在你看来你选择的这三个样本点分别代表什么类型的企业（客户）？对每一个你选择的样本客户，通过它在每一种产品类型上的花费与数据集的统计描述进行比较，给出你做上述判断的理由。</p>
<p><strong>提示：</strong> 企业的类型包括超市、咖啡馆、零售商以及其他。注意不要使用具体企业的名字，比如说在描述一个餐饮业客户时，你不能使用麦当劳。</p>
<p><strong>回答:第一个可能是咖啡厅 Milk 和 Grocery的购买需求高于平均值 第二个可能是餐厅 Fresh Milk Grocery Detergents_Paper Delicatessen都高于平均值 第三个可能是生鲜超市 Fresh 和 Frozen的需求要大些</strong></p>
<h3 id="练习-特征相关性"><a href="#练习-特征相关性" class="headerlink" title="练习: 特征相关性"></a>练习: 特征相关性</h3><p>一个有趣的想法是，考虑这六个类别中的一个（或者多个）产品类别，是否对于理解客户的购买行为具有实际的相关性。也就是说，当用户购买了一定数量的某一类产品，我们是否能够确定他们必然会成比例地购买另一种类的产品。有一个简单的方法可以检测相关性：我们用移除了某一个特征之后的数据集来构建一个监督学习（回归）模型，然后用这个模型去预测那个被移除的特征，再对这个预测结果进行评分，看看预测结果如何。</p>
<p>在下面的代码单元中，你需要实现以下的功能：</p>
<ul>
<li>使用 <code>DataFrame.drop</code> 函数移除数据集中你选择的不需要的特征，并将移除后的结果赋值给 <code>new_data</code> 。</li>
<li>使用 <code>sklearn.model_selection.train_test_split</code> 将数据集分割成训练集和测试集。<ul>
<li>使用移除的特征作为你的目标标签。设置 <code>test_size</code> 为 <code>0.25</code> 并设置一个 <code>random_state</code> 。</li>
</ul>
</li>
</ul>
<ul>
<li>导入一个 DecisionTreeRegressor （决策树回归器），设置一个 <code>random_state</code>，然后用训练集训练它。</li>
<li>使用回归器的 <code>score</code> 函数输出模型在测试集上的预测得分。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：为DataFrame创建一个副本，用'drop'函数丢弃一个特征# TODO： </span></span><br><span class="line">new_data = data.drop(<span class="string">'Detergents_Paper'</span>, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：使用给定的特征作为目标，将数据分割成训练集和测试集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(new_data, data[<span class="string">'Detergents_Paper'</span>], test_size=<span class="number">0.25</span>, random_state=<span class="number">40</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：创建一个DecisionTreeRegressor（决策树回归器）并在训练集上训练它</span></span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeRegressor</span><br><span class="line">regressor = DecisionTreeRegressor(random_state=<span class="number">0</span>)</span><br><span class="line">regressor.fit(X_train, y_train)</span><br><span class="line"><span class="comment"># TODO：输出在测试集上的预测得分</span></span><br><span class="line">score = regressor.score(X_test, y_test)</span><br><span class="line">print(score)</span><br></pre></td></tr></table></figure>
<pre><code>0.7879942418323117
</code></pre><h3 id="问题-2"><a href="#问题-2" class="headerlink" title="问题 2"></a>问题 2</h3><p>你尝试预测哪一个特征？预测的得分是多少？这个特征对于区分用户的消费习惯来说必要吗？为什么？<br><strong>提示：</strong> 决定系数（coefficient of determination），$R^2$ 结果在0到1之间，1表示完美拟合，一个负的 $R^2$ 表示模型不能够拟合数据。</p>
<p><strong>回答:尝试预测Detergents_Paper 得分为0.787 不必要 该特征与其他特征有一定相关性 决定系数较高 可通过其他特征预测</strong></p>
<h3 id="可视化特征分布"><a href="#可视化特征分布" class="headerlink" title="可视化特征分布"></a>可视化特征分布</h3><p>为了能够对这个数据集有一个更好的理解，我们可以对数据集中的每一个产品特征构建一个散布矩阵（scatter matrix）。如果你发现你在上面尝试预测的特征对于区分一个特定的用户来说是必须的，那么这个特征和其它的特征可能不会在下面的散射矩阵中显示任何关系。相反的，如果你认为这个特征对于识别一个特定的客户是没有作用的，那么通过散布矩阵可以看出在这个数据特征和其它特征中有关联性。运行下面的代码以创建一个散布矩阵。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于数据中的每一对特征构造一个散布矩阵</span></span><br><span class="line">pd.scatter_matrix(data, alpha = <span class="number">0.3</span>, figsize = (<span class="number">14</span>,<span class="number">8</span>), diagonal = <span class="string">'kde'</span>);</span><br></pre></td></tr></table></figure>
<pre><code>C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:2: FutureWarning: pandas.scatter_matrix is deprecated, use pandas.plotting.scatter_matrix instead
</code></pre><p><img src="/2019/02/16/Customer-Setments/output_17_1.png" alt="png"></p>
<h3 id="问题-3"><a href="#问题-3" class="headerlink" title="问题 3"></a>问题 3</h3><p>这里是否存在一些特征他们彼此之间存在一定程度相关性？如果有请列出。这个结果是验证了还是否认了你尝试预测的那个特征的相关性？这些特征的数据是怎么分布的？</p>
<p><strong>提示：</strong> 这些数据是正态分布（normally distributed）的吗？大多数的数据点分布在哪？</p>
<p><strong>回答:特征之间存在一定相关性 在矩阵对角线出现正偏态分布</strong></p>
<h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p>在这个部分，你将通过在数据上做一个合适的缩放，并检测异常点（你可以选择性移除）将数据预处理成一个更好的代表客户的形式。预处理数据是保证你在分析中能够得到显著且有意义的结果的重要环节。</p>
<h3 id="练习-特征缩放"><a href="#练习-特征缩放" class="headerlink" title="练习: 特征缩放"></a>练习: 特征缩放</h3><p>如果数据不是正态分布的，尤其是数据的平均数和中位数相差很大的时候（表示数据非常歪斜）。这时候通常用一个<a href="https://github.com/czcbangkai/translations/blob/master/use_of_logarithms_in_economics/use_of_logarithms_in_economics.pdf" target="_blank" rel="noopener">非线性的缩放</a>是很合适的，<a href="http://econbrowser.com/archives/2014/02/use-of-logarithms-in-economics" target="_blank" rel="noopener">（英文原文）</a> — 尤其是对于金融数据。一种实现这个缩放的方法是使用 <a href="http://scipy.github.io/devdocs/generated/scipy.stats.boxcox.html" target="_blank" rel="noopener">Box-Cox 变换</a>，这个方法能够计算出能够最佳减小数据倾斜的指数变换方法。一个比较简单的并且在大多数情况下都适用的方法是使用自然对数。</p>
<p>在下面的代码单元中，你将需要实现以下功能：</p>
<ul>
<li>使用 <code>np.log</code> 函数在数据 <code>data</code> 上做一个对数缩放，然后将它的副本（不改变原始data的值）赋值给 <code>log_data</code>。 </li>
<li>使用 <code>np.log</code> 函数在样本数据 <code>samples</code> 上做一个对数缩放，然后将它的副本赋值给 <code>log_samples</code>。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：使用自然对数缩放数据</span></span><br><span class="line">log_data = np.log(data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：使用自然对数缩放样本数据</span></span><br><span class="line">log_samples = np.log(samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为每一对新产生的特征制作一个散射矩阵</span></span><br><span class="line">pd.scatter_matrix(log_data, alpha = <span class="number">0.3</span>, figsize = (<span class="number">14</span>,<span class="number">8</span>), diagonal = <span class="string">'kde'</span>);</span><br></pre></td></tr></table></figure>
<pre><code>C:\ProgramData\Anaconda3\lib\site-packages\ipykernel_launcher.py:8: FutureWarning: pandas.scatter_matrix is deprecated, use pandas.plotting.scatter_matrix instead
</code></pre><p><img src="/2019/02/16/Customer-Setments/output_22_1.png" alt="png"></p>
<h3 id="观察"><a href="#观察" class="headerlink" title="观察"></a>观察</h3><p>在使用了一个自然对数的缩放之后，数据的各个特征会显得更加的正态分布。对于任意的你以前发现有相关关系的特征对，观察他们的相关关系是否还是存在的（并且尝试观察，他们的相关关系相比原来是变强了还是变弱了）。</p>
<p>运行下面的代码以观察样本数据在进行了自然对数转换之后如何改变了。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示经过对数变换后的样本数据</span></span><br><span class="line">display(log_samples)</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8.861775</td>
      <td>9.191158</td>
      <td>9.166179</td>
      <td>7.474205</td>
      <td>8.099554</td>
      <td>7.482119</td>
    </tr>
    <tr>
      <th>1</th>
      <td>10.112654</td>
      <td>9.155356</td>
      <td>9.400217</td>
      <td>5.683580</td>
      <td>8.528726</td>
      <td>7.681560</td>
    </tr>
    <tr>
      <th>2</th>
      <td>8.667164</td>
      <td>6.599870</td>
      <td>6.688355</td>
      <td>7.239215</td>
      <td>4.369448</td>
      <td>6.061457</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="练习-异常值检测"><a href="#练习-异常值检测" class="headerlink" title="练习: 异常值检测"></a>练习: 异常值检测</h3><p>对于任何的分析，在数据预处理的过程中检测数据中的异常值都是非常重要的一步。异常值的出现会使得把这些值考虑进去后结果出现倾斜。这里有很多关于怎样定义什么是数据集中的异常值的经验法则。这里我们将使用<a href="http://datapigtechnologies.com/blog/index.php/highlighting-outliers-in-your-data-with-the-tukey-method/" target="_blank" rel="noopener"> Tukey 的定义异常值的方法</a>：一个异常阶（outlier step）被定义成1.5倍的四分位距（interquartile range，IQR）。一个数据点如果某个特征包含在该特征的 IQR 之外的特征，那么该数据点被认定为异常点。</p>
<p>在下面的代码单元中，你需要完成下面的功能：</p>
<ul>
<li>将指定特征的 25th 分位点的值分配给 <code>Q1</code> 。使用 <code>np.percentile</code> 来完成这个功能。</li>
<li>将指定特征的 75th 分位点的值分配给 <code>Q3</code> 。同样的，使用 <code>np.percentile</code> 来完成这个功能。</li>
<li>将指定特征的异常阶的计算结果赋值给 <code>step</code>。</li>
<li>选择性地通过将索引添加到 <code>outliers</code> 列表中，以移除异常值。</li>
</ul>
<p><strong>注意：</strong> 如果你选择移除异常值，请保证你选择的样本点不在这些移除的点当中！<br>一旦你完成了这些功能，数据集将存储在 <code>good_data</code> 中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 对于每一个特征，找到值异常高或者是异常低的数据点</span></span><br><span class="line"><span class="keyword">for</span> feature <span class="keyword">in</span> log_data.keys():</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 计算给定特征的Q1（数据的25th分位点）</span></span><br><span class="line">    Q1 = np.percentile(log_data[feature], <span class="number">25</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 计算给定特征的Q3（数据的75th分位点）</span></span><br><span class="line">    Q3 = np.percentile(log_data[feature], <span class="number">75</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> 使用四分位范围计算异常阶（1.5倍的四分位距）</span></span><br><span class="line">    step = (Q3 - Q1) * <span class="number">1.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 显示异常点</span></span><br><span class="line">    print(<span class="string">"Data points considered outliers for the feature '&#123;&#125;':"</span>.format(feature))</span><br><span class="line">    display(log_data[~((log_data[feature] &gt;= Q1 - step) &amp; (log_data[feature] &lt;= Q3 + step))])</span><br><span class="line">    </span><br><span class="line"><span class="comment"># TODO(可选): 选择你希望移除的数据点的索引</span></span><br><span class="line">outliers  = [<span class="number">65</span>,<span class="number">66</span>,<span class="number">75</span>,<span class="number">128</span>,<span class="number">154</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下代码会移除outliers中索引的数据点, 并储存在good_data中</span></span><br><span class="line">good_data = log_data.drop(log_data.index[outliers]).reset_index(drop = <span class="keyword">True</span>)</span><br></pre></td></tr></table></figure>
<pre><code>Data points considered outliers for the feature &#39;Fresh&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>65</th>
      <td>4.442651</td>
      <td>9.950323</td>
      <td>10.732651</td>
      <td>3.583519</td>
      <td>10.095388</td>
      <td>7.260523</td>
    </tr>
    <tr>
      <th>66</th>
      <td>2.197225</td>
      <td>7.335634</td>
      <td>8.911530</td>
      <td>5.164786</td>
      <td>8.151333</td>
      <td>3.295837</td>
    </tr>
    <tr>
      <th>81</th>
      <td>5.389072</td>
      <td>9.163249</td>
      <td>9.575192</td>
      <td>5.645447</td>
      <td>8.964184</td>
      <td>5.049856</td>
    </tr>
    <tr>
      <th>95</th>
      <td>1.098612</td>
      <td>7.979339</td>
      <td>8.740657</td>
      <td>6.086775</td>
      <td>5.407172</td>
      <td>6.563856</td>
    </tr>
    <tr>
      <th>96</th>
      <td>3.135494</td>
      <td>7.869402</td>
      <td>9.001839</td>
      <td>4.976734</td>
      <td>8.262043</td>
      <td>5.379897</td>
    </tr>
    <tr>
      <th>128</th>
      <td>4.941642</td>
      <td>9.087834</td>
      <td>8.248791</td>
      <td>4.955827</td>
      <td>6.967909</td>
      <td>1.098612</td>
    </tr>
    <tr>
      <th>171</th>
      <td>5.298317</td>
      <td>10.160530</td>
      <td>9.894245</td>
      <td>6.478510</td>
      <td>9.079434</td>
      <td>8.740337</td>
    </tr>
    <tr>
      <th>193</th>
      <td>5.192957</td>
      <td>8.156223</td>
      <td>9.917982</td>
      <td>6.865891</td>
      <td>8.633731</td>
      <td>6.501290</td>
    </tr>
    <tr>
      <th>218</th>
      <td>2.890372</td>
      <td>8.923191</td>
      <td>9.629380</td>
      <td>7.158514</td>
      <td>8.475746</td>
      <td>8.759669</td>
    </tr>
    <tr>
      <th>304</th>
      <td>5.081404</td>
      <td>8.917311</td>
      <td>10.117510</td>
      <td>6.424869</td>
      <td>9.374413</td>
      <td>7.787382</td>
    </tr>
    <tr>
      <th>305</th>
      <td>5.493061</td>
      <td>9.468001</td>
      <td>9.088399</td>
      <td>6.683361</td>
      <td>8.271037</td>
      <td>5.351858</td>
    </tr>
    <tr>
      <th>338</th>
      <td>1.098612</td>
      <td>5.808142</td>
      <td>8.856661</td>
      <td>9.655090</td>
      <td>2.708050</td>
      <td>6.309918</td>
    </tr>
    <tr>
      <th>353</th>
      <td>4.762174</td>
      <td>8.742574</td>
      <td>9.961898</td>
      <td>5.429346</td>
      <td>9.069007</td>
      <td>7.013016</td>
    </tr>
    <tr>
      <th>355</th>
      <td>5.247024</td>
      <td>6.588926</td>
      <td>7.606885</td>
      <td>5.501258</td>
      <td>5.214936</td>
      <td>4.844187</td>
    </tr>
    <tr>
      <th>357</th>
      <td>3.610918</td>
      <td>7.150701</td>
      <td>10.011086</td>
      <td>4.919981</td>
      <td>8.816853</td>
      <td>4.700480</td>
    </tr>
    <tr>
      <th>412</th>
      <td>4.574711</td>
      <td>8.190077</td>
      <td>9.425452</td>
      <td>4.584967</td>
      <td>7.996317</td>
      <td>4.127134</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>Data points considered outliers for the feature &#39;Milk&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>86</th>
      <td>10.039983</td>
      <td>11.205013</td>
      <td>10.377047</td>
      <td>6.894670</td>
      <td>9.906981</td>
      <td>6.805723</td>
    </tr>
    <tr>
      <th>98</th>
      <td>6.220590</td>
      <td>4.718499</td>
      <td>6.656727</td>
      <td>6.796824</td>
      <td>4.025352</td>
      <td>4.882802</td>
    </tr>
    <tr>
      <th>154</th>
      <td>6.432940</td>
      <td>4.007333</td>
      <td>4.919981</td>
      <td>4.317488</td>
      <td>1.945910</td>
      <td>2.079442</td>
    </tr>
    <tr>
      <th>356</th>
      <td>10.029503</td>
      <td>4.897840</td>
      <td>5.384495</td>
      <td>8.057377</td>
      <td>2.197225</td>
      <td>6.306275</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>Data points considered outliers for the feature &#39;Grocery&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>75</th>
      <td>9.923192</td>
      <td>7.036148</td>
      <td>1.098612</td>
      <td>8.390949</td>
      <td>1.098612</td>
      <td>6.882437</td>
    </tr>
    <tr>
      <th>154</th>
      <td>6.432940</td>
      <td>4.007333</td>
      <td>4.919981</td>
      <td>4.317488</td>
      <td>1.945910</td>
      <td>2.079442</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>Data points considered outliers for the feature &#39;Frozen&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>38</th>
      <td>8.431853</td>
      <td>9.663261</td>
      <td>9.723703</td>
      <td>3.496508</td>
      <td>8.847360</td>
      <td>6.070738</td>
    </tr>
    <tr>
      <th>57</th>
      <td>8.597297</td>
      <td>9.203618</td>
      <td>9.257892</td>
      <td>3.637586</td>
      <td>8.932213</td>
      <td>7.156177</td>
    </tr>
    <tr>
      <th>65</th>
      <td>4.442651</td>
      <td>9.950323</td>
      <td>10.732651</td>
      <td>3.583519</td>
      <td>10.095388</td>
      <td>7.260523</td>
    </tr>
    <tr>
      <th>145</th>
      <td>10.000569</td>
      <td>9.034080</td>
      <td>10.457143</td>
      <td>3.737670</td>
      <td>9.440738</td>
      <td>8.396155</td>
    </tr>
    <tr>
      <th>175</th>
      <td>7.759187</td>
      <td>8.967632</td>
      <td>9.382106</td>
      <td>3.951244</td>
      <td>8.341887</td>
      <td>7.436617</td>
    </tr>
    <tr>
      <th>264</th>
      <td>6.978214</td>
      <td>9.177714</td>
      <td>9.645041</td>
      <td>4.110874</td>
      <td>8.696176</td>
      <td>7.142827</td>
    </tr>
    <tr>
      <th>325</th>
      <td>10.395650</td>
      <td>9.728181</td>
      <td>9.519735</td>
      <td>11.016479</td>
      <td>7.148346</td>
      <td>8.632128</td>
    </tr>
    <tr>
      <th>420</th>
      <td>8.402007</td>
      <td>8.569026</td>
      <td>9.490015</td>
      <td>3.218876</td>
      <td>8.827321</td>
      <td>7.239215</td>
    </tr>
    <tr>
      <th>429</th>
      <td>9.060331</td>
      <td>7.467371</td>
      <td>8.183118</td>
      <td>3.850148</td>
      <td>4.430817</td>
      <td>7.824446</td>
    </tr>
    <tr>
      <th>439</th>
      <td>7.932721</td>
      <td>7.437206</td>
      <td>7.828038</td>
      <td>4.174387</td>
      <td>6.167516</td>
      <td>3.951244</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>Data points considered outliers for the feature &#39;Detergents_Paper&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>75</th>
      <td>9.923192</td>
      <td>7.036148</td>
      <td>1.098612</td>
      <td>8.390949</td>
      <td>1.098612</td>
      <td>6.882437</td>
    </tr>
    <tr>
      <th>161</th>
      <td>9.428190</td>
      <td>6.291569</td>
      <td>5.645447</td>
      <td>6.995766</td>
      <td>1.098612</td>
      <td>7.711101</td>
    </tr>
  </tbody>
</table>
</div>


<pre><code>Data points considered outliers for the feature &#39;Delicatessen&#39;:
</code></pre><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>66</th>
      <td>2.197225</td>
      <td>7.335634</td>
      <td>8.911530</td>
      <td>5.164786</td>
      <td>8.151333</td>
      <td>3.295837</td>
    </tr>
    <tr>
      <th>109</th>
      <td>7.248504</td>
      <td>9.724899</td>
      <td>10.274568</td>
      <td>6.511745</td>
      <td>6.728629</td>
      <td>1.098612</td>
    </tr>
    <tr>
      <th>128</th>
      <td>4.941642</td>
      <td>9.087834</td>
      <td>8.248791</td>
      <td>4.955827</td>
      <td>6.967909</td>
      <td>1.098612</td>
    </tr>
    <tr>
      <th>137</th>
      <td>8.034955</td>
      <td>8.997147</td>
      <td>9.021840</td>
      <td>6.493754</td>
      <td>6.580639</td>
      <td>3.583519</td>
    </tr>
    <tr>
      <th>142</th>
      <td>10.519646</td>
      <td>8.875147</td>
      <td>9.018332</td>
      <td>8.004700</td>
      <td>2.995732</td>
      <td>1.098612</td>
    </tr>
    <tr>
      <th>154</th>
      <td>6.432940</td>
      <td>4.007333</td>
      <td>4.919981</td>
      <td>4.317488</td>
      <td>1.945910</td>
      <td>2.079442</td>
    </tr>
    <tr>
      <th>183</th>
      <td>10.514529</td>
      <td>10.690808</td>
      <td>9.911952</td>
      <td>10.505999</td>
      <td>5.476464</td>
      <td>10.777768</td>
    </tr>
    <tr>
      <th>184</th>
      <td>5.789960</td>
      <td>6.822197</td>
      <td>8.457443</td>
      <td>4.304065</td>
      <td>5.811141</td>
      <td>2.397895</td>
    </tr>
    <tr>
      <th>187</th>
      <td>7.798933</td>
      <td>8.987447</td>
      <td>9.192075</td>
      <td>8.743372</td>
      <td>8.148735</td>
      <td>1.098612</td>
    </tr>
    <tr>
      <th>203</th>
      <td>6.368187</td>
      <td>6.529419</td>
      <td>7.703459</td>
      <td>6.150603</td>
      <td>6.860664</td>
      <td>2.890372</td>
    </tr>
    <tr>
      <th>233</th>
      <td>6.871091</td>
      <td>8.513988</td>
      <td>8.106515</td>
      <td>6.842683</td>
      <td>6.013715</td>
      <td>1.945910</td>
    </tr>
    <tr>
      <th>285</th>
      <td>10.602965</td>
      <td>6.461468</td>
      <td>8.188689</td>
      <td>6.948897</td>
      <td>6.077642</td>
      <td>2.890372</td>
    </tr>
    <tr>
      <th>289</th>
      <td>10.663966</td>
      <td>5.655992</td>
      <td>6.154858</td>
      <td>7.235619</td>
      <td>3.465736</td>
      <td>3.091042</td>
    </tr>
    <tr>
      <th>343</th>
      <td>7.431892</td>
      <td>8.848509</td>
      <td>10.177932</td>
      <td>7.283448</td>
      <td>9.646593</td>
      <td>3.610918</td>
    </tr>
  </tbody>
</table>
</div>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sns.boxplot(data=data, x=<span class="string">'Fresh'</span>, orient=<span class="string">'v'</span>)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x256682c49b0&gt;
</code></pre><p><img src="/2019/02/16/Customer-Setments/output_27_1.png" alt="png"></p>
<h3 id="问题-4"><a href="#问题-4" class="headerlink" title="问题 4"></a>问题 4</h3><p>请列出所有在多于一个特征下被看作是异常的数据点。这些点应该被从数据集中移除吗？为什么？把你认为需要移除的数据点全部加入到到 <code>outliers</code> 变量中。</p>
<p><strong>回答:不应该 共有48个异常值 对于本样本数据一共有400左右样本 占比过大 如果全部移除会对结果有较大影响 会造成数据损失 因此 判断有两个以上异常值的数据再进行移除 所以移除65,66,75,128,154 这5个样本</strong></p>
<h2 id="特征转换"><a href="#特征转换" class="headerlink" title="特征转换"></a>特征转换</h2><p>在这个部分中你将使用主成分分析（PCA）来分析批发商客户数据的内在结构。由于使用PCA在一个数据集上会计算出最大化方差的维度，我们将找出哪一个特征组合能够最好的描绘客户。</p>
<h3 id="练习-主成分分析（PCA）"><a href="#练习-主成分分析（PCA）" class="headerlink" title="练习: 主成分分析（PCA）"></a>练习: 主成分分析（PCA）</h3><p>既然数据被缩放到一个更加正态分布的范围中并且我们也移除了需要移除的异常点，我们现在就能够在 <code>good_data</code> 上使用PCA算法以发现数据的哪一个维度能够最大化特征的方差。除了找到这些维度，PCA 也将报告每一个维度的解释方差比（explained variance ratio）—这个数据有多少方差能够用这个单独的维度来解释。注意 PCA 的一个组成部分（维度）能够被看做这个空间中的一个新的“特征”，但是它是原来数据中的特征构成的。</p>
<p>在下面的代码单元中，你将要实现下面的功能：</p>
<ul>
<li>导入 <code>sklearn.decomposition.PCA</code> 并且将 <code>good_data</code> 用 PCA 并且使用6个维度进行拟合后的结果保存到 <code>pca</code> 中。</li>
<li>使用 <code>pca.transform</code> 将 <code>log_samples</code> 进行转换，并将结果存储到 <code>pca_samples</code> 中。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：通过在good data上进行PCA，将其转换成6个维度</span></span><br><span class="line"><span class="keyword">from</span> sklearn.decomposition <span class="keyword">import</span> PCA</span><br><span class="line">pca = PCA(n_components=<span class="number">6</span>)</span><br><span class="line">pca.fit(good_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：使用上面的PCA拟合将变换施加在log_samples上</span></span><br><span class="line">pca_samples = pca.transform(good_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成PCA的结果图</span></span><br><span class="line">pca_results = vs.pca_results(good_data, pca)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/16/Customer-Setments/output_32_0.png" alt="png"></p>
<h3 id="问题-5"><a href="#问题-5" class="headerlink" title="问题 5"></a>问题 5</h3><p>数据的第一个和第二个主成分<strong>总共</strong>表示了多少的方差？ 前四个主成分呢？使用上面提供的可视化图像，从用户花费的角度来讨论前四个主要成分中每个主成分代表的消费行为并给出你做出判断的理由。</p>
<p><strong>提示：</strong></p>
<ul>
<li>对每个主成分中的特征分析权重的正负和大小。</li>
<li>结合每个主成分权重的正负讨论消费行为。</li>
<li>某一特定维度上的正向增长对应正权特征的增长和负权特征的减少。增长和减少的速率和每个特征的权重相关。<a href="https://onlinecourses.science.psu.edu/stat505/node/54" target="_blank" rel="noopener">参考资料：Interpretation of the Principal Components</a></li>
</ul>
<p><strong>回答:0.72 0.93 第一个 咖啡厅 最大的负权特征是洗涤类商品 第二个 超市 生鲜冻品和鱼的权值最大 第三个 鱼类零售店 鱼的权值最大 第四个 熟食店 熟食的权值占比最大</strong></p>
<h3 id="观察-1"><a href="#观察-1" class="headerlink" title="观察"></a>观察</h3><p>运行下面的代码，查看经过对数转换的样本数据在进行一个6个维度的主成分分析（PCA）之后会如何改变。观察样本数据的前四个维度的数值。考虑这和你初始对样本点的解释是否一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示经过PCA转换的sample log-data</span></span><br><span class="line">display(pd.DataFrame(np.round(pca_samples, <span class="number">4</span>), columns = pca_results.index.values))</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dimension 1</th>
      <th>Dimension 2</th>
      <th>Dimension 3</th>
      <th>Dimension 4</th>
      <th>Dimension 5</th>
      <th>Dimension 6</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.7580</td>
      <td>0.0097</td>
      <td>-0.9590</td>
      <td>-1.6824</td>
      <td>0.2680</td>
      <td>-0.3891</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-1.7887</td>
      <td>-0.8123</td>
      <td>0.2315</td>
      <td>-0.0036</td>
      <td>0.1194</td>
      <td>-0.2106</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-1.8834</td>
      <td>-1.5991</td>
      <td>1.3204</td>
      <td>-0.5432</td>
      <td>-0.3934</td>
      <td>-0.3117</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.1553</td>
      <td>-1.4052</td>
      <td>0.5422</td>
      <td>0.4127</td>
      <td>-0.6865</td>
      <td>0.6409</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-0.7848</td>
      <td>-2.3943</td>
      <td>0.4798</td>
      <td>-0.3483</td>
      <td>-0.3191</td>
      <td>0.0613</td>
    </tr>
    <tr>
      <th>5</th>
      <td>-1.0850</td>
      <td>-0.3243</td>
      <td>-0.2635</td>
      <td>-0.8812</td>
      <td>0.1862</td>
      <td>-0.5347</td>
    </tr>
    <tr>
      <th>6</th>
      <td>-1.1286</td>
      <td>0.2629</td>
      <td>-1.3162</td>
      <td>-0.5369</td>
      <td>-0.4836</td>
      <td>0.1097</td>
    </tr>
    <tr>
      <th>7</th>
      <td>-1.5672</td>
      <td>-0.9010</td>
      <td>0.3684</td>
      <td>-0.2682</td>
      <td>-0.4571</td>
      <td>0.1526</td>
    </tr>
    <tr>
      <th>8</th>
      <td>-0.8636</td>
      <td>0.6650</td>
      <td>-0.5376</td>
      <td>-0.7922</td>
      <td>-0.1551</td>
      <td>0.0344</td>
    </tr>
    <tr>
      <th>9</th>
      <td>-2.8734</td>
      <td>-0.6774</td>
      <td>0.1330</td>
      <td>-0.1802</td>
      <td>-0.0250</td>
      <td>0.1224</td>
    </tr>
    <tr>
      <th>10</th>
      <td>-2.0887</td>
      <td>-0.7006</td>
      <td>0.8537</td>
      <td>1.0105</td>
      <td>-0.5587</td>
      <td>0.2495</td>
    </tr>
    <tr>
      <th>11</th>
      <td>1.0120</td>
      <td>-0.0103</td>
      <td>-0.7516</td>
      <td>-0.0545</td>
      <td>-0.4333</td>
      <td>0.6602</td>
    </tr>
    <tr>
      <th>12</th>
      <td>-2.2406</td>
      <td>-1.2419</td>
      <td>-1.0729</td>
      <td>-1.9589</td>
      <td>0.2160</td>
      <td>-0.1782</td>
    </tr>
    <tr>
      <th>13</th>
      <td>-1.8891</td>
      <td>-1.3001</td>
      <td>-1.1945</td>
      <td>0.9689</td>
      <td>-0.2426</td>
      <td>0.2970</td>
    </tr>
    <tr>
      <th>14</th>
      <td>-2.3388</td>
      <td>-0.9013</td>
      <td>-1.1515</td>
      <td>-1.6713</td>
      <td>-0.0485</td>
      <td>-0.0739</td>
    </tr>
    <tr>
      <th>15</th>
      <td>0.4258</td>
      <td>0.8803</td>
      <td>-1.2189</td>
      <td>-0.7945</td>
      <td>-0.7319</td>
      <td>0.3868</td>
    </tr>
    <tr>
      <th>16</th>
      <td>-2.7939</td>
      <td>2.0377</td>
      <td>0.3420</td>
      <td>-1.2847</td>
      <td>0.1457</td>
      <td>-0.1353</td>
    </tr>
    <tr>
      <th>17</th>
      <td>0.2575</td>
      <td>-0.5179</td>
      <td>1.1702</td>
      <td>-1.5806</td>
      <td>0.4159</td>
      <td>-0.5328</td>
    </tr>
    <tr>
      <th>18</th>
      <td>-1.3906</td>
      <td>-1.8004</td>
      <td>0.0301</td>
      <td>-0.3807</td>
      <td>-0.2116</td>
      <td>0.1467</td>
    </tr>
    <tr>
      <th>19</th>
      <td>-0.9992</td>
      <td>0.4720</td>
      <td>-0.9332</td>
      <td>-0.1723</td>
      <td>-0.4229</td>
      <td>0.5269</td>
    </tr>
    <tr>
      <th>20</th>
      <td>-0.8375</td>
      <td>-1.0765</td>
      <td>-0.3684</td>
      <td>-0.8111</td>
      <td>-0.5111</td>
      <td>-0.3040</td>
    </tr>
    <tr>
      <th>21</th>
      <td>1.7467</td>
      <td>0.1939</td>
      <td>0.2753</td>
      <td>0.6012</td>
      <td>-0.7470</td>
      <td>0.1974</td>
    </tr>
    <tr>
      <th>22</th>
      <td>-0.1419</td>
      <td>-2.7722</td>
      <td>0.3293</td>
      <td>0.3928</td>
      <td>-1.3904</td>
      <td>0.2012</td>
    </tr>
    <tr>
      <th>23</th>
      <td>-2.8096</td>
      <td>-3.6459</td>
      <td>1.0567</td>
      <td>-0.5186</td>
      <td>0.6999</td>
      <td>-0.1811</td>
    </tr>
    <tr>
      <th>24</th>
      <td>-2.0709</td>
      <td>-2.4853</td>
      <td>0.2692</td>
      <td>-0.4013</td>
      <td>-0.1917</td>
      <td>0.1027</td>
    </tr>
    <tr>
      <th>25</th>
      <td>-1.2292</td>
      <td>1.5540</td>
      <td>-3.2462</td>
      <td>0.0043</td>
      <td>0.1124</td>
      <td>-0.0697</td>
    </tr>
    <tr>
      <th>26</th>
      <td>1.9083</td>
      <td>-0.3765</td>
      <td>0.1924</td>
      <td>0.1502</td>
      <td>-0.3852</td>
      <td>0.5367</td>
    </tr>
    <tr>
      <th>27</th>
      <td>2.4162</td>
      <td>0.6069</td>
      <td>-0.7652</td>
      <td>-1.3209</td>
      <td>0.1614</td>
      <td>0.8089</td>
    </tr>
    <tr>
      <th>28</th>
      <td>-3.5695</td>
      <td>-0.9977</td>
      <td>0.9477</td>
      <td>-0.5400</td>
      <td>0.2579</td>
      <td>0.0323</td>
    </tr>
    <tr>
      <th>29</th>
      <td>0.5684</td>
      <td>-1.0850</td>
      <td>-1.4044</td>
      <td>-0.5784</td>
      <td>-0.6738</td>
      <td>-0.2157</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>405</th>
      <td>-0.4777</td>
      <td>-0.3472</td>
      <td>0.3116</td>
      <td>-0.3929</td>
      <td>-0.9402</td>
      <td>0.1142</td>
    </tr>
    <tr>
      <th>406</th>
      <td>0.7424</td>
      <td>0.0059</td>
      <td>2.1018</td>
      <td>-0.9815</td>
      <td>0.2461</td>
      <td>-0.0371</td>
    </tr>
    <tr>
      <th>407</th>
      <td>-2.1528</td>
      <td>5.3859</td>
      <td>0.0930</td>
      <td>0.4023</td>
      <td>0.3577</td>
      <td>0.3111</td>
    </tr>
    <tr>
      <th>408</th>
      <td>-0.0741</td>
      <td>-1.6911</td>
      <td>1.6461</td>
      <td>1.4172</td>
      <td>0.0587</td>
      <td>0.1461</td>
    </tr>
    <tr>
      <th>409</th>
      <td>0.5554</td>
      <td>-0.0029</td>
      <td>-0.2440</td>
      <td>1.6316</td>
      <td>-0.4586</td>
      <td>-0.0161</td>
    </tr>
    <tr>
      <th>410</th>
      <td>-1.5972</td>
      <td>-0.8047</td>
      <td>0.1483</td>
      <td>-0.0839</td>
      <td>-0.3191</td>
      <td>-0.0512</td>
    </tr>
    <tr>
      <th>411</th>
      <td>-2.5495</td>
      <td>0.1090</td>
      <td>-0.1921</td>
      <td>-0.0073</td>
      <td>-0.0074</td>
      <td>-0.3327</td>
    </tr>
    <tr>
      <th>412</th>
      <td>-1.9218</td>
      <td>0.5424</td>
      <td>-0.4014</td>
      <td>-0.8837</td>
      <td>-0.1168</td>
      <td>0.1580</td>
    </tr>
    <tr>
      <th>413</th>
      <td>-3.2940</td>
      <td>2.4621</td>
      <td>0.3317</td>
      <td>-0.9146</td>
      <td>0.1175</td>
      <td>0.1444</td>
    </tr>
    <tr>
      <th>414</th>
      <td>-0.3359</td>
      <td>-0.0856</td>
      <td>-0.1970</td>
      <td>-1.0176</td>
      <td>-0.6091</td>
      <td>-0.7771</td>
    </tr>
    <tr>
      <th>415</th>
      <td>-3.0266</td>
      <td>1.8034</td>
      <td>-1.1358</td>
      <td>-2.9577</td>
      <td>-0.4264</td>
      <td>0.1528</td>
    </tr>
    <tr>
      <th>416</th>
      <td>-1.4571</td>
      <td>-1.0316</td>
      <td>-0.5676</td>
      <td>-0.6119</td>
      <td>-0.4132</td>
      <td>0.1330</td>
    </tr>
    <tr>
      <th>417</th>
      <td>0.4422</td>
      <td>-0.7142</td>
      <td>-0.9356</td>
      <td>-0.9923</td>
      <td>-0.7925</td>
      <td>0.4116</td>
    </tr>
    <tr>
      <th>418</th>
      <td>-0.4191</td>
      <td>-0.4595</td>
      <td>-1.0590</td>
      <td>-0.2384</td>
      <td>-0.2853</td>
      <td>-0.1660</td>
    </tr>
    <tr>
      <th>419</th>
      <td>-1.0698</td>
      <td>0.0957</td>
      <td>-1.8679</td>
      <td>0.3247</td>
      <td>-0.2282</td>
      <td>0.6291</td>
    </tr>
    <tr>
      <th>420</th>
      <td>2.3699</td>
      <td>-1.7726</td>
      <td>1.3282</td>
      <td>0.7617</td>
      <td>0.4672</td>
      <td>0.1593</td>
    </tr>
    <tr>
      <th>421</th>
      <td>-2.0740</td>
      <td>-1.5983</td>
      <td>-0.0683</td>
      <td>0.4013</td>
      <td>-0.0483</td>
      <td>0.0983</td>
    </tr>
    <tr>
      <th>422</th>
      <td>0.4545</td>
      <td>-2.6564</td>
      <td>0.0980</td>
      <td>1.1628</td>
      <td>1.4384</td>
      <td>-0.5162</td>
    </tr>
    <tr>
      <th>423</th>
      <td>-0.1223</td>
      <td>0.6924</td>
      <td>0.0667</td>
      <td>0.9488</td>
      <td>0.6363</td>
      <td>-0.2967</td>
    </tr>
    <tr>
      <th>424</th>
      <td>1.4269</td>
      <td>1.2099</td>
      <td>-0.1030</td>
      <td>-3.9222</td>
      <td>0.6257</td>
      <td>0.5211</td>
    </tr>
    <tr>
      <th>425</th>
      <td>-0.0856</td>
      <td>0.4483</td>
      <td>1.0450</td>
      <td>-1.3292</td>
      <td>1.1732</td>
      <td>1.1231</td>
    </tr>
    <tr>
      <th>426</th>
      <td>-0.2111</td>
      <td>-1.6998</td>
      <td>0.8104</td>
      <td>1.4239</td>
      <td>-0.0610</td>
      <td>-0.2023</td>
    </tr>
    <tr>
      <th>427</th>
      <td>0.1304</td>
      <td>0.5643</td>
      <td>-1.9278</td>
      <td>-1.1452</td>
      <td>-0.7829</td>
      <td>0.4971</td>
    </tr>
    <tr>
      <th>428</th>
      <td>0.9382</td>
      <td>0.6387</td>
      <td>1.3840</td>
      <td>-0.3231</td>
      <td>-0.0505</td>
      <td>-0.7708</td>
    </tr>
    <tr>
      <th>429</th>
      <td>-1.0055</td>
      <td>-0.3825</td>
      <td>-1.0855</td>
      <td>-0.6019</td>
      <td>-0.2346</td>
      <td>0.1880</td>
    </tr>
    <tr>
      <th>430</th>
      <td>0.6448</td>
      <td>-2.8583</td>
      <td>0.6377</td>
      <td>0.5879</td>
      <td>1.9515</td>
      <td>0.7170</td>
    </tr>
    <tr>
      <th>431</th>
      <td>3.1848</td>
      <td>-1.9448</td>
      <td>0.2677</td>
      <td>-0.6799</td>
      <td>-0.2663</td>
      <td>-0.5194</td>
    </tr>
    <tr>
      <th>432</th>
      <td>-3.7425</td>
      <td>-0.8561</td>
      <td>-0.9885</td>
      <td>-0.8879</td>
      <td>0.0503</td>
      <td>0.2058</td>
    </tr>
    <tr>
      <th>433</th>
      <td>1.6691</td>
      <td>-0.3980</td>
      <td>0.5161</td>
      <td>-1.3189</td>
      <td>0.0913</td>
      <td>0.0056</td>
    </tr>
    <tr>
      <th>434</th>
      <td>0.7390</td>
      <td>3.6914</td>
      <td>-2.0335</td>
      <td>-0.9927</td>
      <td>0.3109</td>
      <td>-0.1734</td>
    </tr>
  </tbody>
</table>
<p>435 rows × 6 columns</p>
</div>


<h3 id="练习：降维"><a href="#练习：降维" class="headerlink" title="练习：降维"></a>练习：降维</h3><p>当使用主成分分析的时候，一个主要的目的是减少数据的维度，这实际上降低了问题的复杂度。当然降维也是需要一定代价的：更少的维度能够表示的数据中的总方差更少。因为这个，<strong>累计解释方差比（cumulative explained variance ratio）</strong>对于我们确定这个问题需要多少维度非常重要。另外，如果大部分的方差都能够通过两个或者是三个维度进行表示的话，降维之后的数据能够被可视化。</p>
<p>在下面的代码单元中，你将实现下面的功能：</p>
<ul>
<li>将 <code>good_data</code> 用两个维度的PCA进行拟合，并将结果存储到 <code>pca</code> 中去。</li>
<li>使用 <code>pca.transform</code> 将 <code>good_data</code> 进行转换，并将结果存储在 <code>reduced_data</code> 中。</li>
<li>使用 <code>pca.transform</code> 将 <code>log_samples</code> 进行转换，并将结果存储在 <code>pca_samples</code> 中。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：通过在good data上进行PCA，将其转换成两个维度</span></span><br><span class="line">pca = PCA(n_components=<span class="number">2</span>)</span><br><span class="line">pca.fit(good_data)</span><br><span class="line"><span class="comment"># TODO：使用上面训练的PCA将good data进行转换</span></span><br><span class="line">reduced_data = pca.transform(good_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：使用上面训练的PCA将log_samples进行转换</span></span><br><span class="line">pca_samples = pca.transform(log_samples)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 为降维后的数据创建一个DataFrame</span></span><br><span class="line">reduced_data = pd.DataFrame(reduced_data, columns = [<span class="string">'Dimension 1'</span>, <span class="string">'Dimension 2'</span>])</span><br></pre></td></tr></table></figure>
<h3 id="观察-2"><a href="#观察-2" class="headerlink" title="观察"></a>观察</h3><p>运行以下代码观察当仅仅使用两个维度进行 PCA 转换后，这个对数样本数据将怎样变化。观察这里的结果与一个使用六个维度的 PCA 转换相比较时，前两维的数值是保持不变的。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 展示经过两个维度的PCA转换之后的样本log-data</span></span><br><span class="line">display(pd.DataFrame(np.round(pca_samples, <span class="number">4</span>), columns = [<span class="string">'Dimension 1'</span>, <span class="string">'Dimension 2'</span>]))</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Dimension 1</th>
      <th>Dimension 2</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-1.7887</td>
      <td>-0.8123</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-2.3388</td>
      <td>-0.9013</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.2785</td>
      <td>0.9078</td>
    </tr>
  </tbody>
</table>
</div>


<h2 id="可视化一个双标图（Biplot）"><a href="#可视化一个双标图（Biplot）" class="headerlink" title="可视化一个双标图（Biplot）"></a>可视化一个双标图（Biplot）</h2><p>双标图是一个散点图，每个数据点的位置由它所在主成分的分数确定。坐标系是主成分（这里是 <code>Dimension 1</code> 和 <code>Dimension 2</code>）。此外，双标图还展示出初始特征在主成分上的投影。一个双标图可以帮助我们理解降维后的数据，发现主成分和初始特征之间的关系。</p>
<p>运行下面的代码来创建一个降维后数据的双标图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 可视化双标图</span></span><br><span class="line">vs.biplot(good_data, reduced_data, pca)</span><br></pre></td></tr></table></figure>
<pre><code>&lt;matplotlib.axes._subplots.AxesSubplot at 0x256683adc88&gt;
</code></pre><p><img src="/2019/02/16/Customer-Setments/output_42_1.png" alt="png"></p>
<h3 id="观察-3"><a href="#观察-3" class="headerlink" title="观察"></a>观察</h3><p>一旦我们有了原始特征的投影（红色箭头），就能更加容易的理解散点图每个数据点的相对位置。</p>
<p>在这个双标图中，哪些初始特征与第一个主成分有强关联？哪些初始特征与第二个主成分相关联？你观察到的是否与之前得到的 pca_results 图相符？</p>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><p>在这个部分，你讲选择使用 K-Means 聚类算法或者是高斯混合模型聚类算法以发现数据中隐藏的客户分类。然后，你将从簇中恢复一些特定的关键数据点，通过将它们转换回原始的维度和规模，从而理解他们的含义。</p>
<h3 id="问题-6"><a href="#问题-6" class="headerlink" title="问题 6"></a>问题 6</h3><p>使用 K-Means 聚类算法的优点是什么？使用高斯混合模型聚类算法的优点是什么？基于你现在对客户数据的观察结果，你选用了这两个算法中的哪一个，为什么？</p>
<p><strong>回答:K-Means优点是：计算速度快、时间短，易解释，聚类效果还不错；但缺点主要是需要提前确定K值，对异常值极度敏感。 高斯混合模型聚类算法的优点是聚类输出的信息量更大，理论上可以拟合任何连续的概率密度函数。 我会选高斯混合模型，因为两种算法聚类得分差异很小，且GMM能输出数据点属于某一类别的概率，因此输出的信息丰富程度大大高于K-means算法</strong></p>
<h3 id="练习-创建聚类"><a href="#练习-创建聚类" class="headerlink" title="练习: 创建聚类"></a>练习: 创建聚类</h3><p>针对不同情况，有些问题你需要的聚类数目可能是已知的。但是在聚类数目不作为一个<strong>先验</strong>知道的情况下，我们并不能够保证某个聚类的数目对这个数据是最优的，因为我们对于数据的结构（如果存在的话）是不清楚的。但是，我们可以通过计算每一个簇中点的<strong>轮廓系数</strong>来衡量聚类的质量。数据点的<a href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.silhouette_score.html" target="_blank" rel="noopener">轮廓系数</a>衡量了它与分配给他的簇的相似度，这个值范围在-1（不相似）到1（相似）。<strong>平均</strong>轮廓系数为我们提供了一种简单地度量聚类质量的方法。</p>
<p>在接下来的代码单元中，你将实现下列功能：</p>
<ul>
<li>在 <code>reduced_data</code> 上使用一个聚类算法，并将结果赋值到 <code>clusterer</code>，需要设置  <code>random_state</code> 使得结果可以复现。</li>
<li>使用 <code>clusterer.predict</code> 预测 <code>reduced_data</code> 中的每一个点的簇，并将结果赋值到 <code>preds</code>。</li>
<li>使用算法的某个属性值找到聚类中心，并将它们赋值到 <code>centers</code>。</li>
<li>预测 <code>pca_samples</code> 中的每一个样本点的类别并将结果赋值到 <code>sample_preds</code>。</li>
<li>导入 <code>sklearn.metrics.silhouette_score</code> 包并计算 <code>reduced_data</code> 相对于 <code>preds</code> 的轮廓系数。<ul>
<li>将轮廓系数赋值给 <code>score</code> 并输出结果。</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：在降维后的数据上使用你选择的聚类算法</span></span><br><span class="line"><span class="keyword">from</span> sklearn.mixture <span class="keyword">import</span> GaussianMixture</span><br><span class="line">clusterer = GaussianMixture(n_components=<span class="number">2</span>, random_state=<span class="number">40</span>)</span><br><span class="line">clusterer.fit(reduced_data)</span><br><span class="line"><span class="comment"># TODO：预测每一个点的簇</span></span><br><span class="line">preds = clusterer.predict(reduced_data)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：找到聚类中心</span></span><br><span class="line">centers = clusterer.means_</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：预测在每一个转换后的样本点的类</span></span><br><span class="line">sample_preds = clusterer.predict(pca_samples)</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score</span><br><span class="line"><span class="comment"># TODO：计算选择的类别的平均轮廓系数（mean silhouette coefficient）</span></span><br><span class="line">score = silhouette_score(reduced_data, preds)</span><br><span class="line">print(score)</span><br></pre></td></tr></table></figure>
<pre><code>0.4219168464626149
</code></pre><h3 id="问题-7"><a href="#问题-7" class="headerlink" title="问题 7"></a>问题 7</h3><p>汇报你尝试的不同的聚类数对应的轮廓系数。在这些当中哪一个聚类的数目能够得到最佳的轮廓系数？</p>
<p><strong>回答:聚类为2时 0.421 聚类为3时 0.375 聚类为4时0.248 所以聚类为2时效果最佳</strong></p>
<h3 id="聚类可视化"><a href="#聚类可视化" class="headerlink" title="聚类可视化"></a>聚类可视化</h3><p>一旦你选好了通过上面的评价函数得到的算法的最佳聚类数目，你就能够通过使用下面的代码块可视化来得到的结果。作为实验，你可以试着调整你的聚类算法的聚类的数量来看一下不同的可视化结果。但是你提供的最终的可视化图像必须和你选择的最优聚类数目一致。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 从已有的实现中展示聚类的结果</span></span><br><span class="line">vs.cluster_results(reduced_data, preds, centers, pca_samples)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/16/Customer-Setments/output_52_0.png" alt="png"></p>
<h3 id="练习-数据恢复"><a href="#练习-数据恢复" class="headerlink" title="练习: 数据恢复"></a>练习: 数据恢复</h3><p>上面的可视化图像中提供的每一个聚类都有一个中心点。这些中心（或者叫平均点）并不是数据中真实存在的点，但是是所有预测在这个簇中的数据点的平均。对于创建客户分类的问题，一个簇的中心对应于那个分类的平均用户。因为这个数据现在进行了降维并缩放到一定的范围，我们可以通过施加一个反向的转换恢复这个点所代表的用户的花费。</p>
<p>在下面的代码单元中，你将实现下列的功能：</p>
<ul>
<li>使用 <code>pca.inverse_transform</code> 将 <code>centers</code> 反向转换，并将结果存储在 <code>log_centers</code> 中。</li>
<li>使用 <code>np.log</code> 的反函数 <code>np.exp</code> 反向转换 <code>log_centers</code> 并将结果存储到 <code>true_centers</code> 中。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># TODO：反向转换中心点</span></span><br><span class="line">log_centers = pca.inverse_transform(centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># TODO：对中心点做指数转换</span></span><br><span class="line">true_centers = np.exp(log_centers)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示真实的中心点</span></span><br><span class="line">segments = [<span class="string">'Segment &#123;&#125;'</span>.format(i) <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">0</span>,len(centers))]</span><br><span class="line">true_centers = pd.DataFrame(np.round(true_centers), columns = data.keys())</span><br><span class="line">true_centers.index = segments</span><br><span class="line">display(true_centers)</span><br></pre></td></tr></table></figure>
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Fresh</th>
      <th>Milk</th>
      <th>Grocery</th>
      <th>Frozen</th>
      <th>Detergents_Paper</th>
      <th>Delicatessen</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Segment 0</th>
      <td>3552.0</td>
      <td>7837.0</td>
      <td>12219.0</td>
      <td>870.0</td>
      <td>4696.0</td>
      <td>962.0</td>
    </tr>
    <tr>
      <th>Segment 1</th>
      <td>8953.0</td>
      <td>2114.0</td>
      <td>2765.0</td>
      <td>2075.0</td>
      <td>353.0</td>
      <td>732.0</td>
    </tr>
  </tbody>
</table>
</div>


<h3 id="问题-8"><a href="#问题-8" class="headerlink" title="问题 8"></a>问题 8</h3><p>考虑上面的代表性数据点在每一个产品类型的花费总数，你认为这些客户分类代表了哪类客户？为什么？需要参考在项目最开始得到的统计值来给出理由。</p>
<p><strong>提示：</strong> 一个被分到<code>&#39;Cluster X&#39;</code>的客户最好被用 <code>&#39;Segment X&#39;</code>中的特征集来标识的企业类型表示。</p>
<p><strong>回答:Segment 0 代表餐厅 食品类出售比重较大 Segment 1 代表超市 基本符合超市出售商品特征</strong></p>
<h3 id="问题-9"><a href="#问题-9" class="headerlink" title="问题 9"></a>问题 9</h3><p>对于每一个样本点<strong>问题 8 </strong>中的哪一个分类能够最好的表示它？你之前对样本的预测和现在的结果相符吗？</p>
<p>运行下面的代码单元以找到每一个样本点被预测到哪一个簇中去。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 显示预测结果</span></span><br><span class="line"><span class="keyword">for</span> i, pred <span class="keyword">in</span> enumerate(sample_preds):</span><br><span class="line">    print(<span class="string">"Sample point"</span>, i, <span class="string">"predicted to be in Cluster"</span>, pred)</span><br></pre></td></tr></table></figure>
<pre><code>Sample point 0 predicted to be in Cluster 0
Sample point 1 predicted to be in Cluster 0
Sample point 2 predicted to be in Cluster 1
</code></pre><p><strong>回答:cluster0 结果不太相符 原数据分类比较细致 这里我们只是使用了2个簇 </strong></p>
<h2 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h2><p>在最后一部分中，你要学习如何使用已经被分类的数据。首先，你要考虑不同组的客户<strong>客户分类</strong>，针对不同的派送策略受到的影响会有什么不同。其次，你要考虑到，每一个客户都被打上了标签（客户属于哪一个分类）可以给客户数据提供一个多一个特征。最后，你会把客户分类与一个数据中的隐藏变量做比较，看一下这个分类是否辨识了特定的关系。</p>
<h3 id="问题-10"><a href="#问题-10" class="headerlink" title="问题 10"></a>问题 10</h3><p>在对他们的服务或者是产品做细微的改变的时候，公司经常会使用 <a href="https://en.wikipedia.org/wiki/A/B_testing" target="_blank" rel="noopener">A/B tests </a>以确定这些改变会对客户产生积极作用还是消极作用。这个批发商希望考虑将他的派送服务从每周5天变为每周3天，但是他只会对他客户当中对此有积极反馈的客户采用。这个批发商应该如何利用客户分类来知道哪些客户对它的这个派送策略的改变有积极的反馈，如果有的话？你需要给出在这个情形下A/B 测试具体的实现方法，以及最终得出结论的依据是什么？</p>
<p><strong>提示：</strong> 我们能假设这个改变对所有的客户影响都一致吗？我们怎样才能够确定它对于哪个类型的客户影响最大？</p>
<p><strong>回答：对两组客户分别为A1;A2,B1;B2 A1参照组 A2实验组 分别应用每周5天和每周3天的服务 分别记录每组的周均销售额 如果A2组的销售额较高 则说明该组对该类客户组有积极作用 然后对A1 A2组 使用新的策略否则保持不变 同理B1,B2采取同样的方式</strong></p>
<h3 id="问题-11"><a href="#问题-11" class="headerlink" title="问题 11"></a>问题 11</h3><p>通过聚类技术，我们能够将原有的没有标记的数据集中的附加结构分析出来。因为每一个客户都有一个最佳的划分（取决于你选择使用的聚类算法），我们可以把用户分类作为数据的一个<a href="https://en.wikipedia.org/wiki/Feature_learning#Unsupervised_feature_learning" target="_blank" rel="noopener">工程特征</a>。假设批发商最近迎来十位新顾客，并且他已经为每位顾客每个产品类别年度采购额进行了预估。进行了这些估算之后，批发商该如何运用它的预估和非监督学习的结果来对这十个新的客户进行更好的预测？</p>
<p><strong>提示</strong>：在下面的代码单元中，我们提供了一个已经做好聚类的数据（聚类结果为数据中的cluster属性），我们将在这个数据集上做一个小实验。尝试运行下面的代码看看我们尝试预测‘Region’的时候，如果存在聚类特征’cluster’与不存在相比对最终的得分会有什么影响？这对你有什么启发？</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取包含聚类结果的数据</span></span><br><span class="line">cluster_data = pd.read_csv(<span class="string">"cluster.csv"</span>)</span><br><span class="line">y = cluster_data[<span class="string">'Region'</span>]</span><br><span class="line">X = cluster_data.drop([<span class="string">'Region'</span>], axis = <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 划分训练集测试集</span></span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=<span class="number">0.2</span>, random_state=<span class="number">24</span>)</span><br><span class="line"></span><br><span class="line">clf = RandomForestClassifier(random_state=<span class="number">24</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">score_with_cluster = clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 移除cluster特征</span></span><br><span class="line">X_train = X_train.copy()</span><br><span class="line">X_train.drop([<span class="string">'cluster'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">X_test = X_test.copy()</span><br><span class="line">X_test.drop([<span class="string">'cluster'</span>], axis=<span class="number">1</span>, inplace=<span class="keyword">True</span>)</span><br><span class="line">clf.fit(X_train, y_train)</span><br><span class="line">score_no_cluster = clf.score(X_test, y_test)</span><br><span class="line"></span><br><span class="line">print(<span class="string">"不使用cluster特征的得分: %.4f"</span>%score_no_cluster)</span><br><span class="line">print(<span class="string">"使用cluster特征的得分: %.4f"</span>%score_with_cluster)</span><br></pre></td></tr></table></figure>
<pre><code>不使用cluster特征的得分: 0.6437
使用cluster特征的得分: 0.6667


C:\ProgramData\Anaconda3\lib\site-packages\sklearn\ensemble\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.
  from numpy.core.umath_tests import inner1d
</code></pre><p><strong>回答：cluster特征对用户的影响较小 但使用caluster有益于精度提高</strong></p>
<h3 id="可视化内在的分布"><a href="#可视化内在的分布" class="headerlink" title="可视化内在的分布"></a>可视化内在的分布</h3><p>在这个项目的开始，我们讨论了从数据集中移除 <code>&#39;Channel&#39;</code> 和 <code>&#39;Region&#39;</code> 特征，这样在分析过程中我们就会着重分析用户产品类别。通过重新引入 <code>Channel</code> 这个特征到数据集中，并施加和原来数据集同样的 PCA 变换的时候我们将能够发现数据集产生一个有趣的结构。</p>
<p>运行下面的代码单元以查看哪一个数据点在降维的空间中被标记为 <code>&#39;HoReCa&#39;</code> (旅馆/餐馆/咖啡厅)或者 <code>&#39;Retail&#39;</code>。另外，你将发现样本点在图中被圈了出来，用以显示他们的标签。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 根据‘Channel‘数据显示聚类的结果</span></span><br><span class="line">vs.channel_results(reduced_data, outliers, pca_samples)</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/16/Customer-Setments/output_67_0.png" alt="png"></p>
<h3 id="问题-12"><a href="#问题-12" class="headerlink" title="问题 12"></a>问题 12</h3><p>你选择的聚类算法和聚类点的数目，与内在的旅馆/餐馆/咖啡店和零售商的分布相比，有足够好吗？根据这个分布有没有哪个簇能够刚好划分成’零售商’或者是’旅馆/饭店/咖啡馆’？你觉得这个分类和前面你对于用户分类的定义是一致的吗？</p>
<p><strong>回答: 基本一致 零售类也属于超市的范围 所有都一样因为特征不多 很多分类比较模糊</strong></p>
<blockquote>
<p><strong>注意</strong>: 当你写完了所有的代码，并且回答了所有的问题。你就可以把你的 iPython Notebook 导出成 HTML 文件。你可以在菜单栏，这样导出<strong>File -&gt; Download as -&gt; HTML (.html)</strong>把这个 HTML 和这个 iPython notebook 一起做为你的作业提交。  </p>
</blockquote>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href target="_blank">Lucifer</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2019/02/16/动态规划/" class="pre-post btn btn-default" title="强化学习(一) 动态规划">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">强化学习(一) 动态规划</span>
        </a>
    
    
        <a href="/2019/02/16/finding-donors/" class="next-post btn btn-default" title="finding donors">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">finding donors</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>






                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">Table of Contents</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#机器学习纳米学位"><span class="toc-text">机器学习纳米学位</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#非监督学习"><span class="toc-text">非监督学习</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#项目-3-创建用户分类"><span class="toc-text">项目 3: 创建用户分类</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#开始"><span class="toc-text">开始</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#分析数据"><span class="toc-text">分析数据</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-选择样本"><span class="toc-text">练习: 选择样本</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-1"><span class="toc-text">问题 1</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-特征相关性"><span class="toc-text">练习: 特征相关性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-2"><span class="toc-text">问题 2</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可视化特征分布"><span class="toc-text">可视化特征分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-3"><span class="toc-text">问题 3</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据预处理"><span class="toc-text">数据预处理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-特征缩放"><span class="toc-text">练习: 特征缩放</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#观察"><span class="toc-text">观察</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-异常值检测"><span class="toc-text">练习: 异常值检测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-4"><span class="toc-text">问题 4</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#特征转换"><span class="toc-text">特征转换</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-主成分分析（PCA）"><span class="toc-text">练习: 主成分分析（PCA）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-5"><span class="toc-text">问题 5</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#观察-1"><span class="toc-text">观察</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习：降维"><span class="toc-text">练习：降维</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#观察-2"><span class="toc-text">观察</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#可视化一个双标图（Biplot）"><span class="toc-text">可视化一个双标图（Biplot）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#观察-3"><span class="toc-text">观察</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#聚类"><span class="toc-text">聚类</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-6"><span class="toc-text">问题 6</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-创建聚类"><span class="toc-text">练习: 创建聚类</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-7"><span class="toc-text">问题 7</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#聚类可视化"><span class="toc-text">聚类可视化</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#练习-数据恢复"><span class="toc-text">练习: 数据恢复</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-8"><span class="toc-text">问题 8</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-9"><span class="toc-text">问题 9</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#结论"><span class="toc-text">结论</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-10"><span class="toc-text">问题 10</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-11"><span class="toc-text">问题 11</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#可视化内在的分布"><span class="toc-text">可视化内在的分布</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#问题-12"><span class="toc-text">问题 12</span></a></li></ol></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
        Total:
        <strong id="busuanzi_value_site_pv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
        &nbsp; | &nbsp;
        Visitors:
        <strong id="busuanzi_value_site_uv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2017
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>






    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/app.js?rev=@@hash"></script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>