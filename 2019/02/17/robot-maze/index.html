<!DOCTYPE HTML>
<html lang="null">
<head><meta name="generator" content="Hexo 3.8.0">
    <!--Setting-->
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, user-scalable=no, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta name="renderer" content="webkit|ie-comp|ie-stand">
    <meta name="apple-mobile-web-app-capable" content="单身程序员的小窝">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <meta name="format-detection" content="telephone=no,email=no,adress=no">
    <meta name="browsermode" content="application">
    <meta name="screen-orientation" content="portrait">
    <link rel="dns-prefetch" href="http://yoursite.com">
    <!--SEO-->

    <meta name="keywords" content="Reinforcement learning">


    <meta name="description" content="Section 0 问题描述与完成项目流程1. 问题描述
在该项目中，你将使用强化学习算法，实现一个自动走迷宫机器人。

如上图所示，智能机器人显示在右上角。在我们的迷宫中，有陷阱（红色炸弹）及...">



<meta name="robots" content="all">
<meta name="google" content="all">
<meta name="googlebot" content="all">
<meta name="verify" content="all">

    <!--Title-->


<title>robot maze | 单身程序员的小窝</title>


    <link rel="alternate" href="/atom.xml" title="单身程序员的小窝" type="application/atom+xml">


    <link rel="icon" href="/favicon.ico">

    



<link rel="stylesheet" href="/css/bootstrap.min.css?rev=3.3.7">
<link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/style.css?rev=@@hash">




    
	<div class="hide">
		<script type="text/javascript">
			var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");document.write(unescape("%3Cspan class='cnzz_stat_icon_1263868967 hide' %3E%3Cscript%20src%3D%22https%3A%2F%2Fs95.cnzz.com%2Fz_stat.php%3Fweb_id%3D1272564536%22%3E%3C%2Fscript%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s19.cnzz.com/z_stat.php%3Fid%3D1263868967%26show%3Dpic1' type='text/javascript'%3E%3C/script%3E"));
		</script>
	</div>




    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "https://hm.baidu.com/hm.js?4cc1f2d8f3067386cc5cdb626a202900";
            var s = document.getElementsByTagName("script")[0];
            s.parentNode.insertBefore(hm, s);
        })();
    </script>



    

</head>


</html>
<!--[if lte IE 8]>
<style>
    html{ font-size: 1em }
</style>
<![endif]-->
<!--[if lte IE 9]>
<div style="ie">你使用的浏览器版本过低，为了你更好的阅读体验，请更新浏览器的版本或者使用其他现代浏览器，比如Chrome、Firefox、Safari等。</div>
<![endif]-->

<body>
    <header class="main-header" style="background-image:url(http://snippet.shenliyang.com/img/banner.jpg)">
    <div class="main-header-box">
        <a class="header-avatar" href="/" title="Jindong">
            <img src="/img/avatar.jpg" alt="logo头像" class="img-responsive center-block">
        </a>
        <div class="branding">
        	<!--<h2 class="text-hide">Snippet主题,从未如此简单有趣</h2>-->
            
                <h2> 活成了一个快乐的小×× </h2>
            
    	</div>
    </div>
</header>
    <nav class="main-navigation">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="navbar-header"><span class="nav-toggle-button collapsed pull-right" data-toggle="collapse" data-target="#main-menu" id="mnav">
                    <span class="sr-only"></span>
                        <i class="fa fa-bars"></i>
                    </span>
                    <a class="navbar-brand" href="http://yoursite.com">单身程序员的小窝</a>
                </div>
                <div class="collapse navbar-collapse" id="main-menu">
                    <ul class="menu">
                        
                            <li role="presentation" class="text-center">
                                <a href="/"><i class="fa "></i>Home</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/机器学习/"><i class="fa "></i>MachineLearning</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/深度学习/"><i class="fa "></i>DeepLearning</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/强化学习/"><i class="fa "></i>Reinforcement learning</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/categories/tools/"><i class="fa "></i>Tools</a>
                            </li>
                        
                            <li role="presentation" class="text-center">
                                <a href="/archives/"><i class="fa "></i>History</a>
                            </li>
                        
                    </ul>
                </div>
            </div>
        </div>
    </div>
</nav>
    <section class="content-wrap">
        <div class="container">
            <div class="row">
                <main class="col-md-8 main-content m-post">
                    <p id="process"></p>
<article class="post">
    <div class="post-head">
        <h1 id="robot maze">
            
	            robot maze
            
        </h1>
        <div class="post-meta">
    
        <span class="categories-meta fa-wrap">
            <i class="fa fa-folder-open-o"></i>
            <a class="category-link" href="/categories/强化学习/">强化学习</a>
        </span>
    

    
        <span class="fa-wrap">
            <i class="fa fa-tags"></i>
            <span class="tags-meta">
                
                    <a class="tag-link" href="/tags/Reinforcement-learning/">Reinforcement learning</a>
                
            </span>
        </span>
    

    
        
        <span class="fa-wrap">
            <i class="fa fa-clock-o"></i>
            <span class="date-meta">2019/02/17</span>
        </span>
        
    
</div>
            
            
    </div>
    
    <div class="post-body post-content">
        <h1 id="Section-0-问题描述与完成项目流程"><a href="#Section-0-问题描述与完成项目流程" class="headerlink" title="Section 0 问题描述与完成项目流程"></a>Section 0 问题描述与完成项目流程</h1><h2 id="1-问题描述"><a href="#1-问题描述" class="headerlink" title="1. 问题描述"></a>1. 问题描述</h2><p><img src="/2019/02/17/robot-maze/default.png" width="20%"></p>
<p>在该项目中，你将使用强化学习算法，实现一个自动走迷宫机器人。</p>
<ol>
<li>如上图所示，智能机器人显示在右上角。在我们的迷宫中，有陷阱（红色炸弹）及终点（蓝色的目标点）两种情景。机器人要尽量避开陷阱、尽快到达目的地。</li>
<li>小车可执行的动作包括：向上走 <code>u</code>、向右走 <code>r</code>、向下走 <code>d</code>、向左走 <code>l</code>。</li>
<li>执行不同的动作后，根据不同的情况会获得不同的奖励，具体而言，有以下几种情况。<ul>
<li>撞到墙壁：-10</li>
<li>走到终点：50</li>
<li>走到陷阱：-30</li>
<li>其余情况：-0.1</li>
</ul>
</li>
<li>我们需要通过修改 <code>robot.py</code> 中的代码，来实现一个 Q Learning 机器人，实现上述的目标。</li>
</ol>
<h2 id="2-完成项目流程"><a href="#2-完成项目流程" class="headerlink" title="2. 完成项目流程"></a>2. 完成项目流程</h2><ol>
<li>配置环境，使用 <code>envirnment.yml</code> 文件配置名为 <code>robot-env</code> 的 conda 环境，具体而言，你只需转到当前的目录，在命令行/终端中运行如下代码，稍作等待即可。<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">conda env create -f envirnment.yml</span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>安装完毕后，在命令行/终端中运行 <code>source activate robot-env</code>（Mac/Linux 系统）或 <code>activate robot-env</code>（Windows 系统）激活该环境。</p>
<ol>
<li>阅读 <code>main.ipynb</code> 中的指导完成项目，并根据指导修改对应的代码，生成、观察结果。</li>
<li>导出代码与报告，上传文件，提交审阅并优化。</li>
</ol>
<hr>
<hr>
<h1 id="Section-1-算法理解"><a href="#Section-1-算法理解" class="headerlink" title="Section 1 算法理解"></a>Section 1 算法理解</h1><h2 id="1-1-强化学习总览"><a href="#1-1-强化学习总览" class="headerlink" title="1. 1 强化学习总览"></a>1. 1 强化学习总览</h2><p>强化学习作为机器学习算法的一种，其模式也是让智能体在“训练”中学到“经验”，以实现给定的任务。但不同于监督学习与非监督学习，在强化学习的框架中，我们更侧重通过智能体与环境的<strong>交互</strong>来学习。通常在监督学习和非监督学习任务中，智能体往往需要通过给定的训练集，辅之以既定的训练目标（如最小化损失函数），通过给定的学习算法来实现这一目标。然而在强化学习中，智能体则是通过其与环境交互得到的奖励进行学习。这个环境可以是虚拟的（如虚拟的迷宫），也可以是真实的（自动驾驶汽车在真实道路上收集数据）。</p>
<p>在强化学习中有五个核心组成部分，它们分别是：<strong>环境（Environment）</strong>、<strong>智能体（Agent）</strong>、<strong>状态（State）</strong>、<strong>动作（Action）</strong>和<strong>奖励（Reward）</strong>。在某一时间节点 $t$：</p>
<ul>
<li>智能体在从环境中感知其所处的状态 $s_t$</li>
<li>智能体根据某些准则选择动作 $a_t$</li>
<li>环境根据智能体选择的动作，向智能体反馈奖励 $r_{t+1}$</li>
</ul>
<p>通过合理的学习算法，智能体将在这样的问题设置下，成功学到一个在状态 $s_t$ 选择动作 $a_t$ 的策略 $\pi (s_t) = a_t$。</p>
<hr>
<p><strong>问题 1</strong>：请参照如上的定义，描述出 “机器人走迷宫这个问题” 中强化学习五个组成部分对应的实际对象：</p>
<ul>
<li><strong>环境</strong> : 迷宫中地图的大小还有陷阱的位置会对机器人有一定的影响</li>
<li><strong>状态</strong> : 机器人所处位置</li>
</ul>
<ul>
<li><strong>动作</strong> : 机器人在某一状态时，所处地图某一点所有动作可能的集合，在本项目中 可能向上 下 左 右 四个方向，最终会向奖励最高的方向行走</li>
<li><strong>奖励</strong> : 机器人在前进后退碰到陷阱等得到的奖励并不相同 陷阱会减少很多奖励 前进会获得奖励 后退会减少奖励 可能会遇到 +N 若碰到炸弹或退回会遇到-N的奖励机制</li>
</ul>
<script type="math/tex; mode=display">T(s^{'}, a, s) = P(s^{'}|a,s)</script><hr>
<h2 id="1-2-计算-Q-值"><a href="#1-2-计算-Q-值" class="headerlink" title="1.2 计算 Q 值"></a>1.2 计算 Q 值</h2><p>在我们的项目中，我们要实现基于 Q-Learning 的强化学习算法。Q-Learning 是一个值迭代（Value Iteration）算法。与策略迭代（Policy Iteration）算法不同，值迭代算法会计算每个”状态“或是”状态-动作“的值（Value）或是效用（Utility），然后在执行动作的时候，会设法最大化这个值。因此，对每个状态值的准确估计，是我们值迭代算法的核心。通常我们会考虑<strong>最大化动作的长期奖励</strong>，即不仅考虑当前动作带来的奖励，还会考虑动作长远的奖励。</p>
<p>在 Q-Learning 算法中，我们把这个长期奖励记为 Q 值，我们会考虑每个 ”状态-动作“ 的 Q 值，具体而言，它的计算公式为：</p>
<script type="math/tex; mode=display">
q(s_{t},a) = R_{t+1} + \gamma \times\max_a q(a,s_{t+1})</script><p>也就是对于当前的“状态-动作” $(s<em>{t},a)$，我们考虑执行动作 $a$ 后环境给我们的奖励 $R</em>{t+1}$，以及执行动作 $a$ 到达 $s<em>{t+1}$后，执行任意动作能够获得的最大的Q值 $\max_a q(a,s</em>{t+1})$，$\gamma$ 为折扣因子。</p>
<p>不过一般地，我们使用更为保守地更新 Q 表的方法，即引入松弛变量 $alpha$，按如下的公式进行更新，使得 Q 表的迭代变化更为平缓。</p>
<script type="math/tex; mode=display">
q(s_{t},a) = (1-\alpha) \times q(s_{t},a) + \alpha \times(R_{t+1} + \gamma \times\max_a q(a,s_{t+1}))</script><hr>
<p><img src="/2019/02/17/robot-maze/default2.png" width="20%"></p>
<p><strong>问题 2</strong>：根据已知条件求 $q(s_{t},a)$，在如下模板代码中的空格填入对应的数字即可。</p>
<p>已知：如上图，机器人位于 $s_1$，行动为 <code>u</code>，行动获得的奖励与题目的默认设置相同。在 $s_2$ 中执行各动作的 Q 值为：<code>u</code>: -24，<code>r</code>: -13，<code>d</code>: -0.29、<code>l</code>: +40，$\gamma$ 取0.9。</p>
<script type="math/tex; mode=display">
\begin{align}
q(s_{t},a) & = R_{t+1} + \gamma \times\max_a q(a,s_{t+1}) \\
 & =(-0.1) + (0.9)*(40) \\
 & =(35.9)
\end{align}</script><hr>
<h2 id="1-3-如何选择动作"><a href="#1-3-如何选择动作" class="headerlink" title="1.3 如何选择动作"></a>1.3 如何选择动作</h2><p>在强化学习中，「探索-利用」问题是非常重要的问题。具体来说，根据上面的定义，我们会尽可能地让机器人在每次选择最优的决策，来最大化长期奖励。但是这样做有如下的弊端：</p>
<ol>
<li>在初步的学习中，我们的 Q 值会不准确，如果在这个时候都按照 Q 值来选择，那么会造成错误。</li>
<li>学习一段时间后，机器人的路线会相对固定，则机器人无法对环境进行有效的探索。</li>
</ol>
<p>因此我们需要一种办法，来解决如上的问题，增加机器人的探索。由此我们考虑使用 epsilon-greedy 算法，即在小车选择动作的时候，以一部分的概率随机选择动作，以一部分的概率按照最优的 Q 值选择动作。同时，这个选择随机动作的概率应当随着训练的过程逐步减小。</p>
<hr>
<p><strong>问题 3</strong>：在如下的代码块中，实现 epsilon-greedy 算法的逻辑，并运行测试代码。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"></span><br><span class="line">actions = [<span class="string">'u'</span>,<span class="string">'r'</span>,<span class="string">'d'</span>,<span class="string">'l'</span>]</span><br><span class="line">qline = &#123;<span class="string">'u'</span>:<span class="number">1.2</span>, <span class="string">'r'</span>:<span class="number">-2.1</span>, <span class="string">'d'</span>:<span class="number">-24.5</span>, <span class="string">'l'</span>:<span class="number">27</span>&#125;</span><br><span class="line">epsilon = <span class="number">0.3</span> <span class="comment"># 以0.3的概率进行随机选择</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">choose_action</span><span class="params">(epsilon)</span>:</span></span><br><span class="line">    </span><br><span class="line">    action = <span class="keyword">None</span></span><br><span class="line">    <span class="keyword">if</span> random.uniform(<span class="number">0</span>,<span class="number">1.0</span>) &lt;= epsilon: <span class="comment"># 以某一概率</span></span><br><span class="line">        action = random.choice(actions) <span class="comment"># 实现对动作的随机选择</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        action = max(qline.items(), key=operator.itemgetter(<span class="number">1</span>))[<span class="number">0</span>] <span class="comment"># 否则选择具有最大 Q 值的动作</span></span><br><span class="line">    <span class="keyword">return</span> action</span><br><span class="line"></span><br><span class="line">result = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    result += choose_action(epsilon)</span><br><span class="line"></span><br><span class="line">result</span><br></pre></td></tr></table></figure>
<pre><code>&#39;lllllullurlllulllllllldllllldlulldullulllllllllll...&#39;
</code></pre><hr>
<hr>
<h1 id="Section-2-代码实现"><a href="#Section-2-代码实现" class="headerlink" title="Section 2 代码实现"></a>Section 2 代码实现</h1><h2 id="2-1-Maze-类理解"><a href="#2-1-Maze-类理解" class="headerlink" title="2.1. Maze 类理解"></a>2.1. <code>Maze</code> 类理解</h2><p>我们首先引入了迷宫类 <code>Maze</code>，这是一个非常强大的函数，它能够根据你的要求随机创建一个迷宫，或者根据指定的文件，读入一个迷宫地图信息。</p>
<ol>
<li>使用 <code>Maze(&quot;file_name&quot;)</code> 根据指定文件创建迷宫，或者使用 <code>Maze(maze_size=(height,width))</code> 来随机生成一个迷宫。</li>
<li>使用 <code>trap_number</code> 参数，在创建迷宫的时候，设定迷宫中陷阱的数量。</li>
<li>直接键入迷宫变量的名字按回车，展示迷宫图像（如 <code>g=Maze(&quot;xx.txt&quot;)</code>，那么直接输入 <code>g</code> 即可。</li>
<li>建议生成的迷宫尺寸，长在 6~12 之间，宽在 10～12 之间。</li>
</ol>
<hr>
<p><strong>问题 4</strong>：在如下的代码块中，创建你的迷宫并展示。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Maze <span class="keyword">import</span> Maze</span><br><span class="line">%matplotlib inline</span><br><span class="line">%config InlineBackend.figure_format = <span class="string">'retina'</span></span><br><span class="line"></span><br><span class="line"><span class="comment">## todo: 创建迷宫并展示</span></span><br><span class="line">g = Maze(<span class="string">'test_world/maze_01.txt'</span>)</span><br><span class="line"></span><br><span class="line">g</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/17/robot-maze/output_13_0.png" alt="png"></p>
<pre><code>Maze of size (12, 12)
</code></pre><hr>
<p>你可能已经注意到，在迷宫中我们已经默认放置了一个机器人。实际上，我们为迷宫配置了相应的 API，来帮助机器人的移动与感知。其中你随后会使用的两个 API 为 <code>maze.sense_robot()</code> 及 <code>maze.move_robot()</code>。</p>
<ol>
<li><code>maze.sense_robot()</code> 为一个无参数的函数，输出机器人在迷宫中目前的位置。</li>
<li><code>maze.move_robot(direction)</code> 对输入的移动方向，移动机器人，并返回对应动作的奖励值。</li>
</ol>
<hr>
<p><strong>问题 5</strong>：随机移动机器人，并记录下获得的奖励，展示出机器人最后的位置。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">rewards = []</span><br><span class="line"></span><br><span class="line"><span class="comment">## 循环、随机移动机器人10次，记录下奖励</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>):</span><br><span class="line">    result = g.move_robot(random.choice(actions))</span><br><span class="line">    </span><br><span class="line">    rewards.append(result)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 输出机器人最后的位置</span></span><br><span class="line">print(g.sense_robot)</span><br><span class="line"></span><br><span class="line"><span class="comment">## 打印迷宫，观察机器人位置</span></span><br><span class="line">g</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/17/robot-maze/output_15_0.png" alt="png"></p>
<pre><code>&lt;bound method Maze.sense_robot of Maze of size (12, 12)&gt;
</code></pre><p><img src="/2019/02/17/robot-maze/output_15_2.png" alt="png"></p>
<pre><code>Maze of size (12, 12)
</code></pre><h2 id="2-2-Robot-类实现"><a href="#2-2-Robot-类实现" class="headerlink" title="2.2. Robot 类实现"></a>2.2. <code>Robot</code> 类实现</h2><p><code>Robot</code> 类是我们需要重点实现的部分。在这个类中，我们需要实现诸多功能，以使得我们成功实现一个强化学习智能体。总体来说，之前我们是人为地在环境中移动了机器人，但是现在通过实现 <code>Robot</code> 这个类，机器人将会自己移动。通过实现学习函数，<code>Robot</code> 类将会学习到如何选择最优的动作，并且更新强化学习中对应的参数。</p>
<p>首先 <code>Robot</code> 有多个输入，其中 <code>alpha=0.5, gamma=0.9, epsilon0=0.5</code> 表征强化学习相关的各个参数的默认值，这些在之前你已经了解到，<code>Maze</code> 应为机器人所在迷宫对象。</p>
<p>随后观察 <code>Robot.update</code> 函数，它指明了在每次执行动作时，<code>Robot</code> 需要执行的程序。按照这些程序，各个函数的功能也就明了了。</p>
<p>最后你需要实现 <code>Robot.py</code> 代码中的8段代码，他们都在代码中以 <code>#TODO</code> 进行标注，你能轻松地找到他们。</p>
<hr>
<p><strong>问题 6</strong>：实现 <code>Robot.py</code> 中的8段代码，并运行如下代码检查效果（记得将 <code>maze</code> 变量修改为你创建迷宫的变量名）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> Robot <span class="keyword">import</span> Robot</span><br><span class="line">robot = Robot(g) <span class="comment"># 记得将 maze 变量修改为你创建迷宫的变量名</span></span><br><span class="line">robot.set_status(learning=<span class="keyword">True</span>,testing=<span class="keyword">False</span>)</span><br><span class="line">print(robot.update())</span><br><span class="line"></span><br><span class="line">g</span><br></pre></td></tr></table></figure>
<pre><code>(&#39;u&#39;, -10.0)
</code></pre><p><img src="/2019/02/17/robot-maze/output_19_1.png" alt="png"></p>
<pre><code>Maze of size (12, 12)
</code></pre><hr>
<h2 id="2-3-用-Runner-类训练-Robot"><a href="#2-3-用-Runner-类训练-Robot" class="headerlink" title="2.3 用 Runner 类训练 Robot"></a>2.3 用 <code>Runner</code> 类训练 Robot</h2><p>在实现了上述内容之后，我们就可以开始对我们 <code>Robot</code> 进行训练并调参了。我们为你准备了又一个非常棒的类 <code>Runner</code>，来实现整个训练过程及可视化。使用如下的代码，你可以成功对机器人进行训练。并且你会在当前文件夹中生成一个名为 <code>filename</code> 的视频，记录了整个训练的过程。通过观察该视频，你能够发现训练过程中的问题，并且优化你的代码及参数。</p>
<hr>
<p><strong>问题 7</strong>：尝试利用下列代码训练机器人，并进行调参。可选的参数包括：</p>
<ul>
<li>训练参数<ul>
<li>训练次数 <code>epoch</code></li>
</ul>
</li>
<li>机器人参数：<ul>
<li><code>epsilon0</code> (epsilon 初值)</li>
<li><code>epsilon</code>衰减（可以是线性、指数衰减，可以调整衰减的速度），你需要在 Robot.py 中调整</li>
<li><code>alpha</code></li>
<li><code>gamma</code></li>
</ul>
</li>
<li>迷宫参数:<ul>
<li>迷宫大小</li>
<li>迷宫中陷阱的数量</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">## 可选的参数：</span></span><br><span class="line">epoch = <span class="number">30</span></span><br><span class="line"></span><br><span class="line">epsilon0 = <span class="number">0.8</span></span><br><span class="line">alpha = <span class="number">0.4</span></span><br><span class="line">gamma = <span class="number">0.9</span></span><br><span class="line"></span><br><span class="line">maze_size = (<span class="number">6</span>,<span class="number">8</span>)</span><br><span class="line">trap_number = <span class="number">2</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> Runner <span class="keyword">import</span> Runner</span><br><span class="line"></span><br><span class="line">g = Maze(maze_size=maze_size,trap_number=trap_number)</span><br><span class="line">r = Robot(g,alpha=alpha, epsilon0=epsilon0, gamma=gamma)</span><br><span class="line">r.set_status(learning=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line">runner = Runner(r, g)</span><br><span class="line">runner.run_training(epoch, display_direction=<span class="keyword">True</span>)</span><br><span class="line"><span class="comment">#runner.generate_movie(filename = "final1.mp4") # 你可以注释该行代码，加快运行速度，不过你就无法观察到视频了。?</span></span><br></pre></td></tr></table></figure>
<hr>
<p>使用 <code>runner.plot_results()</code> 函数，能够打印机器人在训练过程中的一些参数信息。</p>
<ul>
<li>Success Times 代表机器人在训练过程中成功的累计次数，这应当是一个累积递增的图像。</li>
<li>Accumulated Rewards 代表机器人在每次训练 epoch 中，获得的累积奖励的值，这应当是一个逐步递增的图像。</li>
<li>Running Times per Epoch 代表在每次训练 epoch 中，小车训练的次数（到达终点就会停止该 epoch 转入下次训练），这应当是一个逐步递减的图像。</li>
</ul>
<hr>
<p><strong>问题 8</strong>：使用 <code>runner.plot_results()</code> 输出训练结果，根据该结果对你的机器人进行分析。</p>
<ul>
<li>指出你选用的参数如何，选用参数的原因。</li>
<li>建议你比较不同参数下机器人的训练的情况。</li>
<li>训练的结果是否满意，有何改进的计划。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">epoch = 30</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">epsilon0 = 0.8</span></span><br><span class="line"><span class="string">alpha = 0.4</span></span><br><span class="line"><span class="string">gamma = 0.9</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">maze_size = (6,8)</span></span><br><span class="line"><span class="string">trap_number = 2</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">runner.plot_results()</span><br></pre></td></tr></table></figure>
<p><img src="/2019/02/17/robot-maze/output_25_0.png" alt="png"></p>
<p>(回答区)<br>epoch统一为30 因为经过多次训练发现当运行到30次左右的时候机器人已经可以很好的找到目标地点<br>我希望机器人能更好的探索地图所以初始的epsilon参数也就是epsilon0参数选择0.6<br>且希望机器人考虑更多新的知识所以讲alpha设置为0.8且降低机器人对未来奖励的考虑一边探索更多的区域所以gamma调整为0.7<br>且上图证明考虑更多新的知识且在一定程度上减少对未来的考虑效果还是很不错的<br>机器人成功的速度会受到地图随机时陷阱的影响，若陷阱挡住进入目标唯一的道路时机器人会无法到达目标（见最后一图），修改奖励机制，若在到达目标的路径上不得不踩陷阱，那就将该陷阱惩罚降低</p>
<hr>

    </div>
    
    <div class="post-footer">
        <div>
            
                转载声明：商业转载请联系作者获得授权,非商业转载请注明出处 © <a href target="_blank">Lucifer</a>
            
        </div>
        <div>
            
        </div>
    </div>
</article>

<div class="article-nav prev-next-wrap clearfix">
    
        <a href="/2019/03/21/ARIMA模型/" class="pre-post btn btn-default" title="ARIMA模型">
            <i class="fa fa-angle-left fa-fw"></i><span class="hidden-lg">上一篇</span>
            <span class="hidden-xs">ARIMA模型</span>
        </a>
    
    
        <a href="/2019/02/16/Explore-Movie-Dataset/" class="next-post btn btn-default" title="Explore Movie Dataset">
            <span class="hidden-lg">下一篇</span>
            <span class="hidden-xs">Explore Movie Dataset</span><i class="fa fa-angle-right fa-fw"></i>
        </a>
    
</div>






                </main>
                
                    <aside id="article-toc" role="navigation" class="col-md-4">
    <div class="widget">
        <h3 class="title">Table of Contents</h3>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Section-0-问题描述与完成项目流程"><span class="toc-text">Section 0 问题描述与完成项目流程</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-问题描述"><span class="toc-text">1. 问题描述</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-完成项目流程"><span class="toc-text">2. 完成项目流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Section-1-算法理解"><span class="toc-text">Section 1 算法理解</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-强化学习总览"><span class="toc-text">1. 1 强化学习总览</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-计算-Q-值"><span class="toc-text">1.2 计算 Q 值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-如何选择动作"><span class="toc-text">1.3 如何选择动作</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Section-2-代码实现"><span class="toc-text">Section 2 代码实现</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-1-Maze-类理解"><span class="toc-text">2.1. Maze 类理解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-2-Robot-类实现"><span class="toc-text">2.2. Robot 类实现</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-3-用-Runner-类训练-Robot"><span class="toc-text">2.3 用 Runner 类训练 Robot</span></a></li></ol></li></ol>
        
    </div>
</aside>

                
            </div>
        </div>
    </section>
    <footer class="main-footer">
    <div class="container">
        <div class="row">
        </div>
    </div>
</footer>

<a id="back-to-top" class="icon-btn hide">
	<i class="fa fa-chevron-up"></i>
</a>




    <div class="copyright">
    <div class="container">
        <div class="row">
            <div class="col-sm-12">
                <div class="busuanzi">
    
        Total:
        <strong id="busuanzi_value_site_pv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
        &nbsp; | &nbsp;
        Visitors:
        <strong id="busuanzi_value_site_uv">
            <i class="fa fa-spinner fa-spin"></i>
        </strong>
    
</div>

            </div>
            <div class="col-sm-12">
                <span>Copyright &copy; 2018
                </span> |
                <span>
                    Powered by <a href="//hexo.io" class="copyright-links" target="_blank" rel="nofollow">Hexo</a>
                </span> |
                <span>
                    Theme by <a href="//github.com/shenliyang/hexo-theme-snippet.git" class="copyright-links" target="_blank" rel="nofollow">Snippet</a>
                </span>
            </div>
        </div>
    </div>
</div>




    <script src="/assets/tagcanvas.min.js?rev=2.9"></script>
    <script>
        var tagOption = {
            textColour: '#444', // 字体颜色
            outlineMethod: 'block', // 选中模式
            outlineColour: '#FFDAB9', // 选中模式的颜色
            interval: 30 || 30, // 动画帧之间的时间间隔，值越大，转动幅度越大
            textHeight: 13,
            outlineRadius: 3,
            freezeActive: true || '', // 选中的标签是否继续滚动
            frontSelect: true || '', // 不选标签云后部的标签
            initial: [0.1, -0.1],
            depth: 0.5,
            decel: 0.95,
            maxSpeed: 0.03,
            reverse: true || '', // 是否反向触发
            fadeIn: 500, // 进入动画时间
            wheelZoom: false || '' // 是否启用鼠标滚轮
        }
        TagCanvas.Start('tag-cloud-3d','',tagOption);
    </script>



    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>


<script src="/js/app.js?rev=@@hash"></script>

</body>
</html>